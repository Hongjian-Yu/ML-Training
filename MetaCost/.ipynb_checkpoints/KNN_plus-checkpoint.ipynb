{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2ab027-afc5-4c80-b1cb-7b7fd763ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics.pairwise import euclidean_distances\n",
    "# from scipy.spatial.distance import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7024c832-aaee-43b2-a738-18ce4f9807d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_distance(x1,x2,feature_label,euclidean,ham):\n",
    "    \n",
    "    euclidean_features = euclidean\n",
    "    hamming_features = ham\n",
    "    # euclidean_features = [i for i in range(0,Wine_data_.shape[1]-1)]\n",
    "    # hamming_features=[]\n",
    "    distance = 0\n",
    "    flag=0\n",
    "    if ham is None:\n",
    "        for i in range(len(feature_label)):\n",
    "            distance+=(x1[i]-x2[i])**2\n",
    "            flag=1\n",
    "    elif euclidean is None:\n",
    "        for i in range(len(feature_label)):\n",
    "            distance+=(x1[i]!=x2[i])\n",
    "    else:\n",
    "        for i in range(len(feature_label)):\n",
    "            if feature_label[i] in euclidean_features:\n",
    "                distance+=(x1[i]-x2[i])**2\n",
    "                flag=1\n",
    "            else:\n",
    "                distance+=(x1[i]!=x2[i])\n",
    "    \n",
    "    if flag==1:\n",
    "        distance = np.sqrt(distance)\n",
    "    # euclidean_dist = euclidean_distances([[x1[i] for i in euclidean_features]], [[x2[i] for i in euclidean_features]])[0][0]\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4981fa-87c1-40b6-8a1e-839c9f331db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object):\n",
    "    def __init__(self,feature_subset_size,train_set,resample_times):\n",
    "        if not isinstance(train_set,pd.DataFrame):\n",
    "            raise ValueError('train_set must be a DataFrame object')\n",
    "        new_index = list(range(len(train_set)))\n",
    "        train_set.index = new_index\n",
    "        colums = [i for i in range(train_set.shape[1]-1)]\n",
    "        self.feature_subset_size = feature_subset_size\n",
    "        self.train_set = train_set[colums]\n",
    "        self.resample_times = resample_times\n",
    "        # self.model = model\n",
    "        self.train_label = train_set.iloc[:,-1].values\n",
    "    \n",
    "    \n",
    "    def fit(self,C,n_neighbor,euclidean_features=None,hamming_features=None):\n",
    "        self.C = C\n",
    "        all_colums_list = self.train_set.columns.tolist()\n",
    "        # remain_colums = [colums_name for colums_name in all_colums_list if colums_name!='target']\n",
    "        S=[]\n",
    "        F=[]\n",
    "        for i in range(self.resample_times):\n",
    "            select_colums = np.random.choice(all_colums_list,self.feature_subset_size,replace=False)\n",
    "            # print(select_colums)\n",
    "            select_ = self.train_set[select_colums].copy()\n",
    "            X = select_.values\n",
    "            # select_['target'] = self.train_label\n",
    "            # print(select_colums)\n",
    "            knn =KNeighborsClassifier(n_neighbors=n_neighbor,metric=custom_distance,metric_params={'feature_label':select_colums,'euclidean':euclidean_features,'ham':hamming_features})\n",
    "            \n",
    "            # new_model = clone(knn)\n",
    "            # knn.effective_metric_params_ = {}\n",
    "                                            \n",
    "            \n",
    "            # knn =KNeighborsClassifier(n_neighbors=2,metric=custom_distance,metric_params={})\n",
    "            # print(\"X:\",X.shape)\n",
    "            # Y = select_['target'].values\n",
    "            Y = self.train_label\n",
    "            S.append(knn.fit(X,Y))\n",
    "            F.append(select_colums)\n",
    "        relabel = []\n",
    "        \n",
    "        for i in range(len(self.train_set)):\n",
    "            P_each_model = np.array([S[j].predict([self.train_set[F[j]].copy().values[i]]) for j in range(len(S))]).flatten()\n",
    "            # print(P_each_model)\n",
    "            unique,counts = np.unique(P_each_model,return_counts=True)\n",
    "            \n",
    "            # print(counts)\n",
    "            P = np.array(counts*1.0 / len(P_each_model))\n",
    "            all_class = np.unique(self.train_label,return_counts=False)\n",
    "            class_cate = {i:0 for i in all_class}\n",
    "            for element, proportion in zip(unique,P):\n",
    "                class_cate[element] = proportion\n",
    "            # print(P)\n",
    "            P_list = np.array([class_cate[j] for j in all_class]) \n",
    "           \n",
    "            relabel.append(np.argmin(self.C.dot(P_list.T)))\n",
    "            \n",
    "        self.relabel = relabel    \n",
    "        \n",
    "        for i in range(len(S)):\n",
    "            S[i].fit(self.train_set[F[i]].copy().values,relabel)    \n",
    "        \n",
    "        self.S = S\n",
    "        self.F = F\n",
    "            \n",
    "    def predict(self,test_set):\n",
    "        F = self.F\n",
    "        S = self.S\n",
    "        # colums = [i for i in range(test_set.shape[1])-1]\n",
    "        self.test_set = test_set.iloc[:,:-1]\n",
    "        self.test_label = test_set.iloc[:,-1].values\n",
    "        label=[]\n",
    "        for i in range(self.resample_times):\n",
    "            sample = self.test_set[F[i]].values\n",
    "            label.append(S[i].predict(sample))\n",
    "        label_ = np.array(label).T\n",
    "        true_label = []\n",
    "        for i in label_:\n",
    "            unique, counts = np.unique(i, return_counts=True)\n",
    "            most_number = unique[np.argmax(counts)]\n",
    "            true_label.append(most_number)\n",
    "       \n",
    "    \n",
    "       \n",
    "        return true_label\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84852119-af81-413b-aa27-4a5e6117f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_cost_matrix(label):\n",
    "#     # np.random.seed(0)\n",
    "#     label_list,counts = np.unique(label,return_counts=True)\n",
    "#     class_number = len(label_list)\n",
    "#     data = np.zeros((class_number,class_number))\n",
    "#     Data = pd.DataFrame(data,columns=label_list,index=label_list)\n",
    "#     for name1 in label_list:\n",
    "#         for name2 in label_list:\n",
    "#             if name1 == name2:\n",
    "#                 Data[name1][name2] = np.random.randint(0,1000)\n",
    "#             else:\n",
    "#                 Data[name1][name2] = np.random.randint(0,2000*counts[np.where(label_list==name1)] / counts[np.where(label_list==name2)])\n",
    "#                 # Data[name1][name2] = np.random.uniform(0,10000)\n",
    "#     return Data\n",
    "# def compute_cs(cost_matrix,true_label,predict_label):\n",
    "#     cs = 0\n",
    "\n",
    "#     for i in range(len(true_label)):\n",
    "        \n",
    "#         # if true_label[i]!=predict_label[i]:\n",
    "#         cs += cost_matrix.iloc[predict_label[i]][true_label[i]]\n",
    "\n",
    "#     # conf_matrix = confusion_matrix(true_label, predict_label)\n",
    "#     # total_cost = np.sum(conf_matrix * cost_matrix.values)\n",
    "\n",
    "#     # return total_cost/len(true_label)\n",
    "#     return cs/len(true_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d5c429-2917-48f6-947b-9ca45eeb69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris = load_iris()\n",
    "# iris_data = iris.data\n",
    "# iris_label = iris.target\n",
    "# iris_ = pd.DataFrame(iris_data)\n",
    "# column = iris_.columns\n",
    "# iris_ = (iris_[column] - iris_[column].min()) / (iris_[column].max() - iris_[column].min())\n",
    "# iris_['Y'] = iris_label\n",
    "# cs = []\n",
    "# cs_k = []\n",
    "\n",
    "# cost_matrix = make_cost_matrix(iris_label)\n",
    "# iris_train_set,iris_test_set = train_test_split(iris_,test_size=0.3,random_state=42)\n",
    "# iris_test_data = iris_test_set.iloc[:,:-1].values\n",
    "# iris_test_label = iris_test_set.iloc[:,-1].values\n",
    "# knn = KNN(2,iris_train_set,10)\n",
    "# knn.fit(cost_matrix.values,euclidean_features=[0,1,2,3])\n",
    "# predict_label = knn.predict(iris_test_set)\n",
    "# print(compute_cs(cost_matrix,iris_test_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3db0984-9fe3-47ba-9d6c-599b0e1793fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_cost_matrix(train_set):\n",
    "#     label_set = train_set['target'].values\n",
    "#     unique,counts = np.unique(label_set,return_counts=True)\n",
    "#     # print(unique)\n",
    "#     # print(counts)\n",
    "#     cost_matrix = np.zeros((len(unique),len(unique)),dtype=int)\n",
    "#     for i in range(len(unique)):\n",
    "#         for j in range(len(unique)):\n",
    "#             if i==j:\n",
    "#                 cost_matrix[i][j] = 0\n",
    "#             else:\n",
    "#                 # print(unique[i],\" \",unique[j])\n",
    "#                 cost_matrix[i][j] = 2000*counts[unique[i]] / counts[unique[j]]\n",
    "#     return cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8ef3da6-849f-40bc-96d7-df1ce0e96495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris = load_iris()\n",
    "# iris_feature = iris.data\n",
    "# iris_class = iris.target\n",
    "# iris_DataFrame_feature= pd.DataFrame(iris_feature)\n",
    "# iris_DataFrame = iris_DataFrame_feature.copy()\n",
    "# iris_DataFrame['target'] = iris_class\n",
    "# train_DataFrame = iris_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745bdc16-05a0-4356-aeec-ac43544dc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine_data = pd.read_csv('data_set/wine.data',header=None)\n",
    "# Wine_data.columns = ['target'] + [i for i in range(0,Wine_data.shape[1]-1)]\n",
    "# unique = np.unique(Wine_data['target'].values,return_counts=False)\n",
    "# replace_dict = {unique[i]:i for i in range(len(unique))}\n",
    "# # print(replace_dict)\n",
    "# Wine_data['target'].replace(replace_dict,inplace=True)\n",
    "# print(Wine_data)\n",
    "# Wine_data_ = (Wine_data.iloc[:,1:]-Wine_data.iloc[:,1:].min())/(Wine_data.iloc[:,1:].max()-Wine_data.iloc[:,1:].min())\n",
    "# Wine_data_['target'] = Wine_data['target'].values\n",
    "# # print(data)\n",
    "# print(Wine_data_)\n",
    "# train_DataFrame = Wine_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e27e11-0c8a-4c0d-8c5a-ac78c0f9e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anneal_data = pd.read_csv('data_set/anneal.data',header=None)\n",
    "# Anneal_data.columns = [i for i in range(0,Anneal_data.shape[1]-1)] + ['target']\n",
    "# # print(Anneal_data)\n",
    "# unique = np.unique(Anneal_data['target'].values,return_counts=False)\n",
    "# replace_dict = {unique[i]:i for i in range(len(unique))}\n",
    "# Anneal_data['target'].replace(replace_dict,inplace=True)\n",
    "\n",
    "# continue_columns = [3,4,8,32,33,34]\n",
    "# scatter_columns = [i for i in range(0,Anneal_data.shape[1]-1) if i not in continue_columns]\n",
    "# for i in scatter_columns:\n",
    "#     unique_ = np.unique(Anneal_data[i].values,return_counts=False)\n",
    "#     replace_ = {unique_[i]:i for i in range(len(unique_))}\n",
    "#     Anneal_data[i].replace(replace_,inplace=True)\n",
    "# train_DataFrame = Anneal_data\n",
    "\n",
    "\n",
    "# # C = np.array([[0, 1000, 1500], [2810, 0, 2292], [11, 16, 0]])\n",
    "# # print(iris_DataFrame)\n",
    "# sums=[]\n",
    "# cs_sum=[]\n",
    "# for i in range(1,37,3):\n",
    "#     train_set,test_set = train_test_split(train_DataFrame,test_size=0.3)\n",
    "#     C = make_cost_matrix(train_set)\n",
    "    \n",
    "#     knn_classifier = KNN(i,train_set,100)\n",
    "#     knn_classifier.fit(C)\n",
    "#     acc,cs = knn_classifier.predict(test_set)\n",
    "#     sums.append(acc)\n",
    "#     cs_sum.append(cs/len(test_set))\n",
    "#     print(\"acc:\",acc,\"   cs:\",cs/len(test_set))\n",
    "   \n",
    "# print(\"average:\",sum(sums)*1.0/len(sums))\n",
    "# print(\"average_cs:\",sum(cs_sum)*1.0/len(cs_sum))\n",
    "# # print(type(sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f0fba83-9846-41b8-a4d7-a34306c7701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # C = np.array([[0, 1000, 1500], [2810, 0, 2292], [11, 16, 0]])\n",
    "# # print(iris_DataFrame)\n",
    "# sums=[]\n",
    "# cs_sum=[]\n",
    "# for i in range(20):\n",
    "#     train_set,test_set = train_test_split(train_DataFrame,test_size=0.3)\n",
    "#     C = make_cost_matrix(train_set)\n",
    "    \n",
    "#     knn_classifier = KNN(6,train_set,50)\n",
    "#     knn_classifier.fit(C,3)\n",
    "#     acc,cs = knn_classifier.predict(test_set)\n",
    "#     sums.append(acc)\n",
    "#     cs_sum.append(cs/len(test_set))\n",
    "#     print(\"acc:\",acc,\"   cs:\",cs/len(test_set))\n",
    "   \n",
    "# print(\"average:\",sum(sums)*1.0/len(sums))\n",
    "# print(\"average_cs:\",sum(cs_sum)*1.0/len(cs_sum))\n",
    "# # print(type(sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162000f5-824a-4182-b95e-9bab77d0fd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a3c4b-7e15-4ad9-80b8-f57677f1de37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
