{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79737907-2a53-4cab-96d0-bdb860cda37b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'continuous_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 140\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# 创建并训练 MFS 分类器\u001b[39;00m\n\u001b[0;32m    139\u001b[0m mfs \u001b[38;5;241m=\u001b[39m MFS(num_classifiers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, subset_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, sampling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwithout_replacement\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 使用 MFS2\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[43mmfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# 预测测试集\u001b[39;00m\n\u001b[0;32m    143\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m mfs\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[1;32mIn[6], line 45\u001b[0m, in \u001b[0;36mMFS.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mrange\u001b[39m(n_features)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscrete_features))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classifiers):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# 随机选择连续特征子集\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcontinuous_features\u001b[49m:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith_replacement\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     47\u001b[0m             continuous_subset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_features, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_features), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset_size), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'continuous_features' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy.spatial.distance import euclidean, hamming\n",
    "\n",
    "class MFS:\n",
    "    def __init__(self, num_classifiers=100, subset_size=None, sampling='with_replacement'):\n",
    "        \"\"\"\n",
    "        初始化 MFS 分类器。\n",
    "\n",
    "        参数：\n",
    "            num_classifiers (int): 要组合的分类器数量。默认为 100。\n",
    "            subset_size (int): 每个分类器使用的特征子集的大小。如果为 None，则默认使用原始特征集大小的一半。\n",
    "            sampling (str):  特征子集的采样方法，可以是 'with_replacement'（有放回采样）或 'without_replacement'（无放回采样）。默认为 'with_replacement'。\n",
    "        \"\"\"\n",
    "        self.num_classifiers = num_classifiers\n",
    "        self.subset_size = subset_size\n",
    "        self.sampling = sampling\n",
    "        self.classifiers = []\n",
    "        self.feature_subsets = []\n",
    "        self.discrete_features = []\n",
    "        self.continuous_features = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        训练 MFS 分类器，同时处理离散特征和连续特征。\n",
    "\n",
    "        参数：\n",
    "            X (array-like, shape (n_samples, n_features)): 训练数据。\n",
    "            y (array-like, shape (n_samples,)):  训练数据的标签。\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        if self.subset_size is None:\n",
    "            self.subset_size = n_features // 2\n",
    "\n",
    "        # 区分离散特征和连续特征\n",
    "        self.discrete_features = [i for i in range(n_features) if isinstance(X[0, i], (int, np.integer))]\n",
    "        self.continuous_features = list(set(range(n_features)) - set(self.discrete_features))\n",
    "\n",
    "        for i in range(self.num_classifiers):\n",
    "            # 随机选择连续特征子集\n",
    "            if continuous_features:\n",
    "                if self.sampling == 'with_replacement':\n",
    "                    continuous_subset = np.random.choice(self.continuous_features, size=min(len(self.continuous_features), self.subset_size), replace=True)\n",
    "                else:\n",
    "                    continuous_subset = np.random.choice(self.continuous_features, size=min(len(self.continuous_features), self.subset_size), replace=False)\n",
    "            else:\n",
    "                continuous_subset = []\n",
    "\n",
    "            # 选择离散特征子集 (示例：使用互信息)\n",
    "            if discrete_features:\n",
    "                n_discrete_features = min(len(self.discrete_features), self.subset_size - len(continuous_subset))\n",
    "                discrete_subset = np.argsort(mutual_info_classif(X[:, self.discrete_features], y))[-n_discrete_features:]\n",
    "            else:\n",
    "                discrete_subset = []\n",
    "\n",
    "            # 合并特征子集\n",
    "            feature_subset = np.concatenate((continuous_subset, discrete_subset)).astype(int)\n",
    "\n",
    "            self.feature_subsets.append(feature_subset)\n",
    "\n",
    "            # 使用选定的特征子集训练 NN 分类器 (使用混合距离)\n",
    "            clf = KNeighborsClassifier(n_neighbors=1, metric=self._mixed_distance)\n",
    "            clf.fit(X[:, feature_subset], y)\n",
    "            self.classifiers.append(clf)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        预测新数据的标签。\n",
    "\n",
    "        参数：\n",
    "            X (array-like, shape (n_samples, n_features)): 要预测的数据。\n",
    "\n",
    "        返回：\n",
    "            array-like, shape (n_samples,): 预测的标签。\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for i in range(self.num_classifiers):\n",
    "            # 使用每个分类器进行预测\n",
    "            prediction = self.classifiers[i].predict(X[:, self.feature_subsets[i]])\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # 使用简单投票法组合预测结果\n",
    "        predictions = np.array(predictions).T  # 转置为 (n_samples, n_classifiers)\n",
    "        final_predictions = []\n",
    "        for i in range(predictions.shape[0]):\n",
    "            # 统计每个样本的投票结果\n",
    "            votes = Counter(predictions[i])\n",
    "            # 选择票数最多的类别作为最终预测结果\n",
    "            final_predictions.append(votes.most_common(1)[0][0])\n",
    "        return np.array(final_predictions)\n",
    "\n",
    "    def _mixed_distance(self, x1, x2):\n",
    "        \"\"\"\n",
    "        计算混合距离，分别使用汉明距离和欧氏距离。\n",
    "\n",
    "        参数：\n",
    "            x1 (array-like, shape (n_features,)):  第一个样本。\n",
    "            x2 (array-like, shape (n_features,)):  第二个样本。\n",
    "\n",
    "        返回：\n",
    "            float: 两个样本之间的距离。\n",
    "        \"\"\"\n",
    "        # 分别提取离散特征和连续特征\n",
    "        x1_discrete = x1[self.discrete_features]\n",
    "        x2_discrete = x2[self.discrete_features]\n",
    "        x1_continuous = x1[self.continuous_features]\n",
    "        x2_continuous = x2[self.continuous_features]\n",
    "\n",
    "        # 计算汉明距离和欧氏距离\n",
    "        if len(self.discrete_features) > 0:\n",
    "            hamming_dist = hamming(x1_discrete, x2_discrete) \n",
    "        else: \n",
    "            hamming_dist = 0\n",
    "\n",
    "        if len(self.continuous_features) > 0:\n",
    "            euclidean_dist = euclidean(x1_continuous, x2_continuous)\n",
    "        else:\n",
    "            euclidean_dist = 0\n",
    "\n",
    "        # 组合距离 (示例:  简单相加)\n",
    "        return hamming_dist + euclidean_dist\n",
    "\n",
    "# 示例用法：\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据集\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 创建并训练 MFS 分类器\n",
    "    mfs = MFS(num_classifiers=100, subset_size=2, sampling='without_replacement')  # 使用 MFS2\n",
    "    mfs.fit(X_train, y_train)\n",
    "\n",
    "    # 预测测试集\n",
    "    y_pred = mfs.predict(X_test)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da617059-7bf9-4d4a-acf9-6039baad9db9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m custom_knn\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# 预测\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcustom_knn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m, in \u001b[0;36mCustomKNN.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:266\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:859\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    857\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 859\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2018\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2016\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2017\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2018\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2020\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2021\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2022\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2024\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2196\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2194\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1766\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1763\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1769\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1810\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1808\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m   1809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m-> 1810\u001b[0m         out[i, j] \u001b[38;5;241m=\u001b[39m metric(X[i], Y[j], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mcustom_distance\u001b[1;34m(x1, x2, selected_features, distance_types)\u001b[0m\n\u001b[0;32m     11\u001b[0m dist_type \u001b[38;5;241m=\u001b[39m distance_types[i]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhamming\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 13\u001b[0m     distance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m hamming([\u001b[43mx1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m], [x2[i]]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 汉明距离\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dist_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     15\u001b[0m     distance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m euclidean_distances([[x1[i]]], [[x2[i]]])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# 欧式距离\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import hamming\n",
    "import random\n",
    "\n",
    "def custom_distance(x1, x2, selected_features, distance_types):\n",
    "    distance = 0.0\n",
    "    for i in selected_features:\n",
    "        dist_type = distance_types[i]\n",
    "        if dist_type == 'hamming':\n",
    "            distance += hamming([x1[i]], [x2[i]]) * 1  # 汉明距离\n",
    "        elif dist_type == 'euclidean':\n",
    "            distance += euclidean_distances([[x1[i]]], [[x2[i]]])[0][0]  # 欧式距离\n",
    "    return distance\n",
    "\n",
    "class CustomKNN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_neighbors=5, distance_types=None):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.distance_types = distance_types\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric=custom_distance, metric_params={})\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 随机选择两个特征\n",
    "        self.selected_features = random.sample(range(X.shape[1]), k=2)\n",
    "        \n",
    "        # 设置 KNN 分类器的距离度量参数\n",
    "        self.knn.metric_params = {'selected_features': self.selected_features, 'distance_types': self.distance_types}\n",
    "        \n",
    "        # 使用 KNN 分类器的 fit 方法进行训练\n",
    "        self.knn.fit(X[:, self.selected_features], y)\n",
    "        \n",
    "        # 返回 self\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.knn.predict(X[:, self.selected_features])\n",
    "\n",
    "# 示例数据集\n",
    "X = np.array([\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 0]\n",
    "])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "\n",
    "# 指定每个特征的距离度量类型\n",
    "distance_types = ['hamming', 'euclidean', 'hamming']\n",
    "\n",
    "# 创建自定义KNN分类器\n",
    "custom_knn = CustomKNN(n_neighbors=3, distance_types=distance_types)\n",
    "\n",
    "# 训练模型\n",
    "custom_knn.fit(X, y)\n",
    "\n",
    "# 预测\n",
    "print(custom_knn.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59a8ac-297a-430e-8b9d-2c87a2c34a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
