{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5e0c9b-e1fc-486d-ac3b-ac9f0accc783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c895b6c0-47c8-42d3-bc68-88f1d7faf280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  4  2\n",
      "1  2  5  3\n",
      "2  3  6  4\n",
      "3  4  7  6\n"
     ]
    }
   ],
   "source": [
    "data = {'A':[1,2,3,4],'B':[4,5,6,7],'C':[2,3,4,6]}\n",
    "data_frame = pd.DataFrame(data)\n",
    "print(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9afe2a9-538b-43e2-adf9-5c69c9cda70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n",
      "3  4  7\n"
     ]
    }
   ],
   "source": [
    "select = data_frame.sample(2,axis=1)\n",
    "print(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4142c371-7cbc-4f4a-950b-80254ec4e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "x = [[1,1],[2,2],[2,1],[1,2]]\n",
    "y = [1,1,1,0]\n",
    "knn.fit(x,y)\n",
    "print(knn.predict([[1,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43cc544-ac99-46a9-a855-44d51f96d345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,2,3],[2,1,2],[2,3,1],[3,2,1]])\n",
    "data_ = data.T\n",
    "for i in data_:\n",
    "    unique, counts = np.unique(i, return_counts=True)\n",
    "    most_number = unique[np.argmax(counts)]\n",
    "    print(most_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a024425-0753-4a5d-a153-3e827269fd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  2\n",
      "1  2  3\n",
      "2  3  4\n",
      "3  4  5\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'A':[1,2,3,4],'B':[2,3,4,5]})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad280cf2-ef9b-492a-af8f-9112e1d6ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['C'] = np.array([3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4483ebd1-18f5-4022-a928-cf146ed27452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  2  3\n",
      "1  2  3  4\n",
      "2  3  4  5\n",
      "3  4  5  6\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7401aae8-44e8-4438-85f2-22bbae3affb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "print(np.random.choice())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b40ed7c-8a07-4a30-b4c1-816f4c88fa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n  Mathematical Statistics\" (John Wiley, NY, 1950).\\n- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n  Structure and Classification Rule for Recognition in Partially Exposed\\n  Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n  Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n  on Information Theory, May 1972, 431-433.\\n- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n  conceptual clustering system finds 3 classes in the data.\\n- Many, many more ...\\n\\n|details-end|', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93800b99-750f-48a4-ba3d-99b6732219a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'A' object has no attribute 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maa\u001b[39m(\u001b[38;5;28mself\u001b[39m,b):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m----> 7\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m a\u001b[38;5;241m.\u001b[39maa(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m, in \u001b[0;36mA.__init__\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,a):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'A' object has no attribute 'b'"
     ]
    }
   ],
   "source": [
    "class A():\n",
    "    def __init__(self,a):\n",
    "        self.a = a\n",
    "    def aa(self,b):\n",
    "        self.b = b\n",
    "a = A(1)\n",
    "a.aa(2)\n",
    "print(a.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47748d7-2adf-4991-a1df-d4e1a3d0b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设你的 NumPy 数组是\n",
    "arr = np.array([0,0,1,1,1,1,1,2,3,3,3,3,0])\n",
    "\n",
    "# 使用 np.unique 来计算每个元素的频次\n",
    "unique_elements= np.unique(arr, return_counts=False)\n",
    "# print(counts)\n",
    "print(unique_elements)\n",
    "# 计算总元素个数\n",
    "total_count = len(arr)\n",
    "\n",
    "# 计算每个元素的比例\n",
    "# proportions = counts / total_count\n",
    "\n",
    "# 打印结果\n",
    "# for element, proportion in zip(unique_elements, proportions):\n",
    "#     print(f\"元素 {element} 的比例是 {proportion:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8c60209-793f-43d1-a9c1-88d3ebd6e4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([[1,2,3],[4,5,6],[1,2,3]])\n",
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c930fb-30c2-46ec-ab35-5ab55111256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始DataFrame:\n",
      "   A   B    C\n",
      "0  1  10  100\n",
      "1  2  20  200\n",
      "2  3  30  300\n",
      "3  4  40  400\n",
      "A      1\n",
      "B     10\n",
      "C    100\n",
      "dtype: int64\n",
      "          B         C\n",
      "0  0.000000  0.000000\n",
      "1  0.333333  0.333333\n",
      "2  0.666667  0.666667\n",
      "3  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [10, 20, 30, 40],\n",
    "    'C': [100, 200, 300, 400]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# print(\"原始DataFrame:\")\n",
    "# print(df)\n",
    "# print(df.min())\n",
    "# # 手动实现Min-Max归一化\n",
    "# def min_max_normalize(df):\n",
    "#     df_normalized = (df.iloc[:,1:] - df.iloc[:,1:].min()) / (df.iloc[:,1:].max() - df.iloc[:,1:].min())\n",
    "#     return df_normalized\n",
    "\n",
    "# df_normalized = min_max_normalize(df)\n",
    "# print(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4580f58-de54-4c70-8270-ce829f71af2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?' 'TN' 'ZS']\n",
      "['C']\n",
      "['?' 'A' 'K' 'M' 'R' 'S' 'V' 'W']\n",
      "[ 0  3  4  6  8 10 45 55 65 70]\n",
      "[ 0 45 50 60 70 80 85]\n",
      "['?' 'T']\n",
      "['?' 'A' 'S']\n",
      "['1' '2' '3' '5' '?']\n",
      "[  0 300 310 350 400 500 600 700]\n",
      "['?' 'N']\n",
      "['?' 'P']\n",
      "['?' 'D' 'E' 'F' 'G']\n",
      "['1' '2' '?']\n",
      "['?' 'Y']\n",
      "['?' 'Y']\n",
      "['?' 'Y']\n",
      "['?' 'B' 'M']\n",
      "['?' 'Y']\n",
      "['?']\n",
      "['?' 'C']\n",
      "['?' 'P']\n",
      "['?' 'Y']\n",
      "['?']\n",
      "['?' 'Y']\n",
      "['?' 'Y']\n",
      "['?']\n",
      "['?' 'B' 'C' 'V']\n",
      "['?' 'Y']\n",
      "['?']\n",
      "['?']\n",
      "['?']\n",
      "['COIL' 'SHEET']\n",
      "[0.25  0.3   0.301 0.321 0.4   0.451 0.5   0.501 0.599 0.6   0.601 0.651\n",
      " 0.699 0.7   0.75  0.799 0.8   0.801 0.9   0.901 0.999 1.    1.001 1.09\n",
      " 1.1   1.2   1.201 1.299 1.3   1.399 1.4   1.5   1.599 1.6   1.601 1.9\n",
      " 2.    2.2   2.3   2.5   2.501 2.8   2.801 3.    3.2   3.201 3.3   3.5\n",
      " 4.   ]\n",
      "[   0.    20.    25.    28.    29.    50.    58.    60.    65.1   75.\n",
      "  150.   152.   190.   200.1  249.9  250.   255.   255.1  300.1  335.\n",
      "  355.   356.   356.1  374.9  375.   385.1  450.   500.   515.   519.\n",
      "  519.9  520.   595.   599.9  600.   600.1  606.9  609.   609.9  610.\n",
      "  640.   710.1  830.   831.9  900.   900.1  915.   915.1  966.   966.1\n",
      " 1000.  1050.  1090.  1100.  1130.  1135.  1200.  1200.1 1220.  1250.\n",
      " 1274.9 1275.  1300.  1310.  1320.  1320.1 1500.  1525. ]\n",
      "[   0    1  150  269  270  300  301  400  610  611  612  614  759  760\n",
      "  761  762  881 1000 1220 3000 4120 4170 4880]\n",
      "['?' 'N' 'Y']\n",
      "[  0 500 600]\n",
      "['2' '3' '?']\n",
      "['1' '2' '3' '5' 'U']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data_set/anneal.data',header=None)\n",
    "data.columns = [i for i in range(0,data.shape[1]-1)] + ['target']\n",
    "for i in range(0,data.shape[1]):\n",
    "    unique = np.unique(data.iloc[:,i].values,return_counts=False)\n",
    "    print(unique)\n",
    "# print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0adaa935-e5a5-4255-bd57-7087b06d1d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import hamming\n",
    "a = np.array(['A','B','C'])\n",
    "b = np.array([1,3,3])\n",
    "print(hamming(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93750965-fc6f-483d-84a1-d86bb788c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 1, 1, 2, 0, 3],\n",
    "    [1, 0, 0, 1, 1, 2],\n",
    "    [0, 0, 1, 1, 0, 1],\n",
    "    [1, 1, 0, 3, 1, 4]\n",
    "])\n",
    "y = np.array([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f19c7ba7-2ce7-4c41-a0e2-c69a22d9231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "7\n",
      "10\n",
      "13\n",
      "16\n",
      "19\n",
      "22\n",
      "25\n",
      "28\n",
      "31\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,37,3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda88855-3a20-4884-901c-9c8790c9562d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
