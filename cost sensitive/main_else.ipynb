{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bda80b-002e-4c63-bb57-21c9490893da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris,load_wine\n",
    "from DecisionTree import D_Tree \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from stratifion import stratified_sampling\n",
    "from MetaCost import Metacost\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from KNN_plus import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d342436-6e30-406c-83df-8b98049602e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_matrix(label):\n",
    "    # np.random.seed(0)\n",
    "    label_list,counts = np.unique(label,return_counts=True)\n",
    "    class_number = len(label_list)\n",
    "    data = np.zeros((class_number,class_number))\n",
    "    Data = pd.DataFrame(data,columns=label_list,index=label_list)\n",
    "    for name1 in label_list:\n",
    "        for name2 in label_list:\n",
    "            if name1 == name2:\n",
    "                Data[name1][name2] = np.random.randint(0,1000)\n",
    "            else:\n",
    "                Data[name1][name2] = np.random.randint(0,2000*counts[np.where(label_list==name1)] / counts[np.where(label_list==name2)])\n",
    "                # Data[name1][name2] = np.random.uniform(0,10000)\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3264791a-3aaf-4914-82cd-15e67b0b1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cs(cost_matrix,true_label,predict_label):\n",
    "    cs = 0\n",
    "\n",
    "    for i in range(len(true_label)):\n",
    "        \n",
    "        # if true_label[i]!=predict_label[i]:\n",
    "        cs += cost_matrix.iloc[predict_label[i]][true_label[i]]\n",
    "\n",
    "    # conf_matrix = confusion_matrix(true_label, predict_label)\n",
    "    # total_cost = np.sum(conf_matrix * cost_matrix.values)\n",
    "\n",
    "    # return total_cost/len(true_label)\n",
    "    return cs/len(true_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd4bce06-52d4-4f47-9302-19721152c5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 629.630193236715\n",
      "C4.5 194.7012777618022\n",
      "under 541.6828502415459\n",
      "under 174.08003920242433\n",
      "over 601.1043478260871\n",
      "over 137.93675126157\n",
      "meta 423.60410628019326\n",
      "meta 199.2296681528701\n",
      "my_algorithm 457.2999999999999\n",
      "my_algorithm 200.40274158956083\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "# fetch dataset \n",
    "statlog_australian_credit_approval = fetch_ucirepo(id=143) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_australian_credit_approval.data.features.values\n",
    "y = statlog_australian_credit_approval.data.targets.values \n",
    "\n",
    "credit_ = pd.DataFrame(X)\n",
    "credit_['Y'] = y\n",
    "cs = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    credit_train_set,credit_test_set = train_test_split(credit_,test_size=0.3,random_state=42)\n",
    "    credit_test_data = credit_test_set.iloc[:,:-1].values\n",
    "    credit_test_label = credit_test_set.iloc[:,-1].values\n",
    "    tree = D_Tree(credit_train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(credit_test_data)\n",
    "    cs.append(compute_cs(cost_matrix,credit_test_label,predict_label))\n",
    "cs = np.array(cs)\n",
    "# print(cs)\n",
    "print(\"C4.5\",np.mean(cs))\n",
    "print(\"C4.5\",np.std(cs))\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    credit_train_set,credit_test_set = train_test_split(credit_,test_size=0.3,random_state=42)\n",
    "    credit_test_data = credit_test_set.iloc[:,:-1].values\n",
    "    credit_test_label = credit_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(credit_train_set,cost_matrix.values,'undersampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(credit_test_data)\n",
    "    cs_.append(compute_cs(cost_matrix,credit_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "# print(cs_)\n",
    "print(\"under\",np.mean(cs_))\n",
    "print(\"under\",np.std(cs_))\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    credit_train_set,credit_test_set = train_test_split(credit_,test_size=0.3,random_state=42)\n",
    "    credit_test_data = credit_test_set.iloc[:,:-1].values\n",
    "    credit_test_label = credit_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(credit_train_set,cost_matrix.values,'oversampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(credit_test_data)\n",
    "    cs_.append(compute_cs(cost_matrix,credit_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "# print(cs_)\n",
    "print(\"over\",np.mean(cs_))\n",
    "print(\"over\",np.std(cs_))\n",
    "\n",
    "cs___=[]\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    credit_train_set,credit_test_set = train_test_split(credit_,test_size=0.3,random_state=42)\n",
    "    credit_test_data = credit_test_set.iloc[:,:-1].values\n",
    "    credit_test_label = credit_test_set.iloc[:,-1].values\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    meta = Metacost(credit_train_set,tree,cost_matrix.values,q=False)\n",
    "    model = meta.fit('Y')\n",
    "    predict_label = model.predict(credit_test_data)\n",
    "    cs___.append(compute_cs(cost_matrix,credit_test_label,predict_label))\n",
    "cs___ = np.array(cs___)\n",
    "# print(cs__)\n",
    "print(\"meta\",np.mean(cs___))\n",
    "print(\"meta\",np.std(cs___))\n",
    "\n",
    "cs_k = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    credit_train_set,credit_test_set = train_test_split(credit_,test_size=0.3,random_state=42)\n",
    "    credit_test_data = credit_test_set.iloc[:,:-1].values\n",
    "    credit_test_label = credit_test_set.iloc[:,-1].values\n",
    "    knn = KNN(2,credit_train_set,50)\n",
    "    knn.fit(cost_matrix.values,n_neighbor=20,euclidean_features=[1,2,6,9,12,13],hamming_features=[0,3,4,5,7,8,10,11])\n",
    "    predict_label = knn.predict(credit_test_set)\n",
    "    cs_k.append(compute_cs(cost_matrix,credit_test_label,predict_label))\n",
    "cs_k = np.array(cs_k)\n",
    "print(\"my_algorithm\",np.mean(cs_k))\n",
    "print(\"my_algorithm\",np.std(cs_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1b06a90-b653-4277-81d4-7bb78692fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 672.5811688311687\n",
      "C4.5 273.2904477628713\n",
      "under 540.4619047619047\n",
      "under 232.44715590680497\n",
      "over 575.8090909090909\n",
      "over 257.57611643868927\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sonar_train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 81\u001b[0m\n\u001b[0;32m     79\u001b[0m pima_test_data \u001b[38;5;241m=\u001b[39m pima_test_set\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     80\u001b[0m pima_test_label \u001b[38;5;241m=\u001b[39m pima_test_set\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m---> 81\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNN(\u001b[38;5;241m6\u001b[39m,\u001b[43msonar_train_set\u001b[49m,\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pima_train_set\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m     83\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(cost_matrix\u001b[38;5;241m.\u001b[39mvalues,n_neighbor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,euclidean_features\u001b[38;5;241m=\u001b[39m[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pima_train_set\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sonar_train_set' is not defined"
     ]
    }
   ],
   "source": [
    "pima = pd.read_csv('pima.dat',header=None)\n",
    "x = pima.iloc[:,:-1].values\n",
    "y = pima.iloc[:,-1].values\n",
    "unique = np.unique(y)\n",
    "change = {unique[i]:i for i in range(len(unique))}\n",
    "y = [change[i] for i in y]\n",
    "pima_ = pd.DataFrame(x)\n",
    "pima_['Y'] = y\n",
    "\n",
    "cs = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    pima_train_set,pima_test_set = train_test_split(pima_,test_size=0.3)\n",
    "    pima_test_data = pima_test_set.iloc[:,:-1].values\n",
    "    pima_test_label = pima_test_set.iloc[:,-1].values\n",
    "    tree = D_Tree(pima_train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(pima_test_data)\n",
    "    \n",
    "    cs.append(compute_cs(cost_matrix,pima_test_label,predict_label))\n",
    "cs = np.array(cs)\n",
    "print(\"C4.5\",cs.mean())\n",
    "print(\"C4.5\",cs.std())\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    pima_train_set,sonar_test_set = train_test_split(pima_,test_size=0.3)\n",
    "    pima_test_data = pima_test_set.iloc[:,:-1].values\n",
    "    pima_test_label = pima_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(pima_train_set,cost_matrix.values,'undersampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(pima_test_data)\n",
    "    cs_.append(compute_cs(cost_matrix,pima_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "print(\"under\",cs_.mean())\n",
    "print(\"under\",cs_.std())\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    pima_train_set,sonar_test_set = train_test_split(pima_,test_size=0.3)\n",
    "    pima_test_data = pima_test_set.iloc[:,:-1].values\n",
    "    pima_test_label = pima_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(pima_train_set,cost_matrix.values,'oversampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(pima_test_data)\n",
    "    cs_.append(compute_cs(cost_matrix,pima_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "print(\"over\",cs_.mean())\n",
    "print(\"over\",cs_.std())\n",
    "\n",
    "# cs___=[]\n",
    "# for i in range(20):\n",
    "#     cost_matrix = make_cost_matrix(y)\n",
    "#     pima_train_set,sonar_test_set = train_test_split(pima_,test_size=0.3,random_state=42)\n",
    "#     pima_test_data = pima_test_set.iloc[:,:-1].values\n",
    "#     pima_test_label = pima_test_set.iloc[:,-1].values\n",
    "#     tree = DecisionTreeClassifier(criterion='entropy')\n",
    "#     meta = Metacost(pima_train_set,tree,cost_matrix.values,q=False)\n",
    "#     model = meta.fit('Y')\n",
    "#     predict_label = model.predict(pima_test_data)\n",
    "#     cs___.append(compute_cs(cost_matrix,pima_test_label,predict_label))\n",
    "# cs___ = np.array(cs___)\n",
    "# # print(cs__)\n",
    "# print(\"meta\",np.mean(cs___))\n",
    "# print(\"meta\",np.std(cs___))\n",
    "\n",
    "cs_k = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    pima_train_set,pima_test_set = train_test_split(pima_,test_size=0.3,random_state=42)\n",
    "    pima_test_data = pima_test_set.iloc[:,:-1].values\n",
    "    pima_test_label = pima_test_set.iloc[:,-1].values\n",
    "    knn = KNN(6,sonar_train_set,50)\n",
    "    print([i for i in range(pima_train_set.shape[1]-1)])\n",
    "    knn.fit(cost_matrix.values,n_neighbor=20,euclidean_features=[i for i in range(pima_train_set.shape[1]-1)])\n",
    "    predict_label = knn.predict(pima_test_set)\n",
    "    cs_k.append(compute_cs(cost_matrix,pima_test_label,predict_label))\n",
    "cs_k = np.array(cs_k)\n",
    "print(\"my_algorithm\",np.mean(cs_k))\n",
    "print(\"my_algorithm\",np.std(cs_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58e1bb-96e9-4dc1-a67e-4c4b7c593913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
