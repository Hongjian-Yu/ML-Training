{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e3f636-bea9-4518-9814-77a07efbe0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris,load_wine\n",
    "from DecisionTree import D_Tree \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from stratifion import stratified_sampling\n",
    "from MetaCost import Metacost\n",
    "from ucimlrepo import fetch_ucirepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f184d647-2887-4767-8688-bd50fc547423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_matrix(label):\n",
    "    # np.random.seed(0)\n",
    "    label_list,counts = np.unique(label,return_counts=True)\n",
    "    class_number = len(label_list)\n",
    "    data = np.zeros((class_number,class_number))\n",
    "    Data = pd.DataFrame(data,columns=label_list,index=label_list)\n",
    "    for name1 in label_list:\n",
    "        for name2 in label_list:\n",
    "            if name1 == name2:\n",
    "                Data[name1][name2] = np.random.randint(0,1000)\n",
    "            else:\n",
    "                Data[name1][name2] = np.random.randint(0,2000*counts[np.where(label_list==name1)] / counts[np.where(label_list==name2)])\n",
    "                # Data[name1][name2] = np.random.uniform(0,10000)\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0ee41f-e8d9-4626-943d-745be116c0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A      B      C\n",
      "A   831.0  470.0  271.0\n",
      "B  5287.0  617.0  871.0\n",
      "C  2782.0  669.0  738.0\n"
     ]
    }
   ],
   "source": [
    "print(make_cost_matrix(['A','A','B','C','A','C','A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da1ae64-66be-4102-8230-f2f5e8235c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cs(cost_matrix,true_label,predict_label):\n",
    "    cs = 0\n",
    "\n",
    "    for i in range(len(true_label)):\n",
    "        \n",
    "        # if true_label[i]!=predict_label[i]:\n",
    "        cs += cost_matrix.iloc[predict_label[i]][true_label[i]]\n",
    "\n",
    "    # conf_matrix = confusion_matrix(true_label, predict_label)\n",
    "    # total_cost = np.sum(conf_matrix * cost_matrix.values)\n",
    "\n",
    "    # return total_cost/len(true_label)\n",
    "    return cs/len(true_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675d62cf-51e6-4293-90f7-7af7e9aea339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(true_label,predict_label):\n",
    "    acc = accuracy_score(true_label,predict_label)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52fc522b-6910-406a-8241-4c0b265c2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_Auc(true_label,predict_label):\n",
    "#     return roc_auc_score(true_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c2a41c-9a38-49fc-bb1f-47077eb4d0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(true_label,predict_label):\n",
    "    return f1_score(true_label,predict_label,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2821e7-844b-46de-affe-2bc8f1e75eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 559.5566666666666\n",
      "C4.5 171.67510507487432\n",
      "under 517.7377777777779\n",
      "under 200.70109580366054\n",
      "over 538.9333333333334\n",
      "over 187.8772800145856\n",
      "meta 379.1744444444445\n",
      "meta 168.53768018817001\n"
     ]
    }
   ],
   "source": [
    "# iris数据集\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "iris_ = pd.DataFrame(iris_data)\n",
    "column = iris_.columns\n",
    "iris_ = (iris_[column] - iris_[column].min()) / (iris_[column].max() - iris_[column].min())\n",
    "iris_['Y'] = iris_label\n",
    "cs = []\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(iris_label)\n",
    "    iris_train_set,iris_test_set = train_test_split(iris_,test_size=0.3,random_state=42)\n",
    "    iris_test_data = iris_test_set.iloc[:,:-1].values\n",
    "    iris_test_label = iris_test_set.iloc[:,-1].values\n",
    "    tree = D_Tree(iris_train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(iris_test_data)\n",
    "    cs.append(compute_cs(cost_matrix,iris_test_label,predict_label))\n",
    "cs = np.array(cs)\n",
    "# print(cs)\n",
    "print(\"C4.5\",np.mean(cs))\n",
    "print(\"C4.5\",np.std(cs))\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(iris_label)\n",
    "    iris_train_set,iris_test_set = train_test_split(iris_,test_size=0.3,random_state=42)\n",
    "    iris_test_data = iris_test_set.iloc[:,:-1].values\n",
    "    iris_test_label = iris_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(iris_train_set,cost_matrix.values,'undersampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(iris_test_data)\n",
    "    cs_.append(compute_cs(cost_matrix,iris_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "# print(cs_)\n",
    "print(\"under\",np.mean(cs_))\n",
    "print(\"under\",np.std(cs_))\n",
    "\n",
    "cs__ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(iris_label)\n",
    "    iris_train_set,iris_test_set = train_test_split(iris_,test_size=0.3,random_state=42)\n",
    "    iris_test_data = iris_test_set.iloc[:,:-1].values\n",
    "    iris_test_label = iris_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(iris_train_set,cost_matrix.values,'oversampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(iris_test_data)\n",
    "    cs__.append(compute_cs(cost_matrix,iris_test_label,predict_label))\n",
    "cs__ = np.array(cs__)\n",
    "# print(cs__)\n",
    "print(\"over\",np.mean(cs__))\n",
    "print(\"over\",np.std(cs__))\n",
    "\n",
    "cs___=[]\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(iris_label)\n",
    "    iris_train_set,iris_test_set = train_test_split(iris_,test_size=0.3,random_state=42)\n",
    "    iris_test_data = iris_test_set.iloc[:,:-1].values\n",
    "    iris_test_label = iris_test_set.iloc[:,-1].values\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    meta = Metacost(iris_train_set,tree,cost_matrix.values,q=False)\n",
    "    model = meta.fit('Y')\n",
    "    predict_label = model.predict(iris_test_data)\n",
    "    cs___.append(compute_cs(cost_matrix,iris_test_label,predict_label))\n",
    "cs___ = np.array(cs___)\n",
    "# print(cs__)\n",
    "print(\"meta\",np.mean(cs___))\n",
    "print(\"meta\",np.std(cs___))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e35a48af-7afd-4a7f-ac99-02285a165999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 521.8601851851852\n",
      "C4.5 184.20632977688277\n",
      "under 495.6935185185186\n",
      "under 183.9136444560666\n",
      "over 500.95370370370364\n",
      "over 157.02340311404032\n",
      "meta 371.84907407407405\n",
      "meta 155.9571698567671\n"
     ]
    }
   ],
   "source": [
    "# Wine数据集\n",
    "wine = load_wine()\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "wine_ = pd.DataFrame(wine_data)\n",
    "wine_['Y'] = wine_label\n",
    "cs = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(wine_label)\n",
    "\n",
    "    wine_train_set,wine_test_set = train_test_split(wine_,test_size=0.3)\n",
    "    wine_test_data = wine_test_set.iloc[:,:-1].values\n",
    "    wine_test_label = wine_test_set.iloc[:,-1].values\n",
    "    tree = D_Tree(wine_train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(wine_test_data)\n",
    "    cs.append(compute_cs(cost_matrix,wine_test_label,predict_label))\n",
    "cs = np.array(cs)\n",
    "print(\"C4.5\",cs.mean())\n",
    "print(\"C4.5\",cs.std())\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(wine_label)\n",
    "    wine_train_set,wine_test_set = train_test_split(wine_,test_size=0.3,random_state=42)\n",
    "    wine_test_data = wine_test_set.iloc[:,:-1].values\n",
    "    wine_test_label = wine_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(wine_train_set,cost_matrix.values,'undersampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(wine_test_data)\n",
    "    cs_.append(compute_cs(cost_matrix,wine_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "# print(cs_)\n",
    "print(\"under\",np.mean(cs_))\n",
    "print(\"under\",np.std(cs_))\n",
    "\n",
    "cs__ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(wine_label)\n",
    "    wine_train_set,wine_test_set = train_test_split(wine_,test_size=0.3,random_state=42)\n",
    "    wine_test_data = wine_test_set.iloc[:,:-1].values\n",
    "    wine_test_label = wine_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(wine_train_set,cost_matrix.values,'oversampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(wine_test_data)\n",
    "    cs__.append(compute_cs(cost_matrix,wine_test_label,predict_label))\n",
    "cs__ = np.array(cs__)\n",
    "# print(cs__)\n",
    "print(\"over\",np.mean(cs__))\n",
    "print(\"over\",np.std(cs__))\n",
    "\n",
    "cs___=[]\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(wine_label)\n",
    "    wine_train_set,wine_test_set = train_test_split(wine_,test_size=0.3,random_state=42)\n",
    "    wine_test_data = wine_test_set.iloc[:,:-1].values\n",
    "    wine_test_label = wine_test_set.iloc[:,-1].values\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    meta = Metacost(wine_train_set,tree,cost_matrix.values,q=False)\n",
    "    model = meta.fit('Y')\n",
    "    predict_label = model.predict(wine_test_data)\n",
    "    cs___.append(compute_cs(cost_matrix,wine_test_label,predict_label))\n",
    "cs___ = np.array(cs___)\n",
    "# print(cs__)\n",
    "print(\"meta\",np.mean(cs___))\n",
    "print(\"meta\",np.std(cs___))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37041705-f182-4d4b-b1f7-e4120be3b831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5: 542.5257407407407\n",
      "C4.5: 239.4899951760058\n"
     ]
    }
   ],
   "source": [
    "annealing = fetch_ucirepo(id=3) \n",
    "anneal_data = annealing.data.features.values\n",
    "anneal_label = annealing.data.targets.values\n",
    "\n",
    "unique = np.unique(anneal_label)\n",
    "\n",
    "change = {unique[i]:i for i in range(len(unique))}\n",
    "\n",
    "a = []\n",
    "for i in anneal_label:\n",
    "\n",
    "    a.append(int(change[i[0]]))\n",
    "anneal_label = a\n",
    "\n",
    "anneal_ = pd.DataFrame(anneal_data)\n",
    "anneal_[38] = anneal_label\n",
    "ann = anneal_\n",
    "\n",
    "colum =  anneal_.columns\n",
    "\n",
    "\n",
    "fea_con = [3,4,8,32,33,34,38]\n",
    "fea_els = [i for i in colum if i not in fea_con]\n",
    "\n",
    "anneal_ = anneal_[colum[fea_els]].astype(str)\n",
    "anneal_ = pd.get_dummies(anneal_)\n",
    "anneal_[colum[fea_con]] = ann[colum[fea_con]].values\n",
    "cs = []\n",
    "for j in range(20):\n",
    "    cost_matrix = make_cost_matrix(anneal_label)\n",
    "    anneal_train_set,anneal_test_set = train_test_split(anneal_,test_size=0.3)\n",
    "    anneal_test_data = anneal_test_set.iloc[:,:-1].values\n",
    "    anneal_test_label = anneal_test_set.iloc[:,-1].values\n",
    "    \n",
    "    t_data = anneal_train_set.iloc[:,:-1].values\n",
    "    t_label = anneal_train_set.iloc[:,-1].values\n",
    "    t_label = [int(i) for i in t_label]\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    tree.fit(t_data,t_label)\n",
    "    \n",
    "    predict_label = tree.predict(anneal_test_data)\n",
    "    \n",
    "    cs.append(compute_cs(cost_matrix,anneal_test_label,predict_label))\n",
    "print(\"C4.5:\",np.mean(cs))\n",
    "print(\"C4.5:\",np.std(cs))\n",
    "\n",
    "# cs_=[]\n",
    "# for j in range(20):\n",
    "#     cost_matrix = make_cost_matrix(anneal_label)\n",
    "#     anneal_train_set,anneal_test_set = train_test_split(anneal_,test_size=0.3)\n",
    "#     anneal_test_data = anneal_test_set.iloc[:,:-1].values\n",
    "#     anneal_test_label = anneal_test_set.iloc[:,-1].values\n",
    "#     t_data,t_label = stratified_sampling(anneal_train_set,cost_matrix,'undersampling')\n",
    "#     t_label = [int(i) for i in t_label]\n",
    "#     tree = DecisionTreeClassifier(criterion='entropy')\n",
    "#     tree.fit(t_data,t_label)\n",
    "#     predict_label = tree.predict(anneal_test_data)\n",
    "#     cs_.append(compute_cs(cost_matrix,anneal_test_label,predict_label))\n",
    "# print(\"undersampling:\",np.mean(cs_))\n",
    "# print(\"undersamping\",np.std(cs_))\n",
    "\n",
    "\n",
    "# cs__=[]\n",
    "# for j in range(20):\n",
    "#     cost_matrix = make_cost_matrix(anneal_label)\n",
    "#     anneal_train_set,anneal_test_set = train_test_split(anneal_,test_size=0.3)\n",
    "#     anneal_test_data = anneal_test_set.iloc[:,:-1].values\n",
    "#     anneal_test_label = anneal_test_set.iloc[:,-1].values\n",
    "#     t_data,t_label = stratified_sampling(anneal_train_set,cost_matrix,'oversampling')\n",
    "#     t_label = [int(i) for i in t_label]\n",
    "#     tree = DecisionTreeClassifier(criterion='entropy')\n",
    "#     tree.fit(t_data,t_label)\n",
    "#     predict_label = tree.predict(anneal_test_data)\n",
    "#     cs__.append(compute_cs(cost_matrix,anneal_test_label,predict_label))\n",
    "# print(\"oversampling:\",np.mean(cs__))\n",
    "# print(\"voersamping\",np.std(cs__))\n",
    "\n",
    "\n",
    "# css_=[]\n",
    "# for j in range(20):\n",
    "#     cost_matrix = make_cost_matrix(anneal_label)\n",
    "#     anneal_train_set,anneal_test_set = train_test_split(anneal_,test_size=0.3)\n",
    "#     # print(anneal_train_set)\n",
    "#     anneal_test_data = anneal_test_set.iloc[:,:-1].values\n",
    "#     anneal_test_label = anneal_test_set.iloc[:,-1].values\n",
    "#     tree = DecisionTreeClassifier(criterion='entropy')\n",
    "#     meta = Metacost(anneal_train_set,tree,cost_matrix.values,q=False)\n",
    "#     new_model = meta.fit(38)\n",
    "#     predict_label  = new_model.predict(anneal_test_data)\n",
    "#     css_.append(compute_cs(cost_matrix,anneal_test_label,predict_label))\n",
    "# print(\"meta\",np.mean(css_))\n",
    "# print(\"meta\",np.std(css_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9f9ad4-4dc5-48fb-baba-a46bb9b13016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 986.5625\n",
      "C4.5 471.1685863029814\n",
      "under 761.2875\n",
      "under 397.8666785573404\n",
      "over 646.79375\n",
      "over 559.4317028174105\n",
      "meta 664.8\n",
      "meta 675.0553268992104\n"
     ]
    }
   ],
   "source": [
    "lenses = fetch_ucirepo(id=58) \n",
    "X = lenses.data.features.values\n",
    "y = lenses.data.targets.values\n",
    "unique = np.unique(y,return_counts=False)\n",
    "change = {unique[i]:i for i in range(len(unique))}\n",
    "# print(y)\n",
    "y = [change[i[0]] for i in y]\n",
    "lenses_ = pd.DataFrame(X)\n",
    "lenses_['Y'] = y\n",
    "\n",
    "cs = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    lenses_train_set,lenses_test_set = train_test_split(lenses_,test_size=0.3)\n",
    "    lenses_test_data = lenses_test_set.iloc[:,:-1].values\n",
    "    lenses_test_label = lenses_test_set.iloc[:,-1].values\n",
    "    tree = D_Tree(lenses_train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(lenses_test_data)\n",
    "    cs.append(compute_cs(cost_matrix,lenses_test_label,predict_label))\n",
    "cs = np.array(cs)\n",
    "print(\"C4.5\",cs.mean())\n",
    "print(\"C4.5\",cs.std())\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    lenses_train_set,lenses_test_set = train_test_split(lenses_,test_size=0.3)\n",
    "    lenses_test_data = lenses_test_set.iloc[:,:-1].values\n",
    "    lenses_test_label = lenses_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(lenses_train_set,cost_matrix.values,'undersampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(lenses_test_data)\n",
    "    cs_.append(compute_cs(cost_matrix,lenses_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "# print(cs_)\n",
    "print(\"under\",np.mean(cs_))\n",
    "print(\"under\",np.std(cs_))\n",
    "\n",
    "cs__ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    lenses_train_set,lenses_test_set = train_test_split(lenses_,test_size=0.3)\n",
    "    lenses_test_data = lenses_test_set.iloc[:,:-1].values\n",
    "    lenses_test_label = lenses_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(lenses_train_set,cost_matrix.values,'oversampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(lenses_test_data)\n",
    "    cs__.append(compute_cs(cost_matrix,lenses_test_label,predict_label))\n",
    "cs__ = np.array(cs__)\n",
    "# print(cs_)\n",
    "print(\"over\",np.mean(cs__))\n",
    "print(\"over\",np.std(cs__))\n",
    "\n",
    "cs___=[]\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    lenses_train_set,wine_test_set = train_test_split(lenses_,test_size=0.3,random_state=42)\n",
    "    lenses_test_data = lenses_test_set.iloc[:,:-1].values\n",
    "    lenses_test_label = lenses_test_set.iloc[:,-1].values\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    meta = Metacost(lenses_train_set,tree,cost_matrix.values,q=False)\n",
    "    model = meta.fit('Y')\n",
    "    predict_label = model.predict(lenses_test_data)\n",
    "    cs___.append(compute_cs(cost_matrix,lenses_test_label,predict_label))\n",
    "cs___ = np.array(cs___)\n",
    "# print(cs__)\n",
    "print(\"meta\",np.mean(cs___))\n",
    "print(\"meta\",np.std(cs___))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "580cf7f2-87a6-4dc8-879c-2996cea10b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 450.8133333333334\n",
      "C4.5 170.77196699432585\n",
      "under 536.09\n",
      "under 166.8769011044435\n",
      "under 551.9866666666668\n",
      "under 131.4475875269937\n",
      "meta 348.40999999999997\n",
      "meta 101.95788079180323\n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "soybean_small = fetch_ucirepo(id=91) \n",
    "X = soybean_small.data.features.values \n",
    "y = soybean_small.data.targets.values\n",
    "unique = np.unique(y,return_counts=False)\n",
    "change = {unique[i]:i for i in range(len(unique))}\n",
    "y = [change[i[0]] for i in y]\n",
    "soybean_ = pd.DataFrame(X)\n",
    "soybean_['Y'] = y\n",
    "\n",
    "\n",
    "cs = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    soybean_train_set,soybean_test_set = train_test_split(soybean_,test_size=0.3)\n",
    "    soybean_test_data = soybean_test_set.iloc[:,:-1].values\n",
    "    soybean_test_label = soybean_test_set.iloc[:,-1].values\n",
    "    tree = D_Tree(soybean_train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(soybean_test_data)\n",
    "    cs.append(compute_cs(cost_matrix,soybean_test_label,predict_label))\n",
    "cs = np.array(cs)\n",
    "print(\"C4.5\",cs.mean())\n",
    "print(\"C4.5\",cs.std())\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    soybean_train_set,soybean_test_set = train_test_split(soybean_,test_size=0.3)\n",
    "    soybean_test_data = soybean_test_set.iloc[:,:-1].values\n",
    "    soybean_test_label = soybean_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(soybean_train_set,cost_matrix.values,'undersampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(soybean_test_data)\n",
    "    cs_.append(compute_cs(cost_matrix,soybean_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "print(\"under\",cs_.mean())\n",
    "print(\"under\",cs_.std())\n",
    "\n",
    "cs__ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    soybean_train_set,soybean_test_set = train_test_split(soybean_,test_size=0.3)\n",
    "    soybean_test_data = soybean_test_set.iloc[:,:-1].values\n",
    "    soybean_test_label = soybean_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(soybean_train_set,cost_matrix.values,'oversampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(soybean_test_data)\n",
    "    cs__.append(compute_cs(cost_matrix,soybean_test_label,predict_label))\n",
    "cs__ = np.array(cs__)\n",
    "print(\"under\",cs__.mean())\n",
    "print(\"under\",cs__.std())\n",
    "\n",
    "\n",
    "cs___=[]\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    soybean_train_set,soybean_test_set = train_test_split(soybean_,test_size=0.3,random_state=42)\n",
    "    soybean_test_data = soybean_test_set.iloc[:,:-1].values\n",
    "    soybean_test_label = soybean_test_set.iloc[:,-1].values\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    meta = Metacost(soybean_train_set,tree,cost_matrix.values,q=False)\n",
    "    model = meta.fit('Y')\n",
    "    predict_label = model.predict(soybean_test_data)\n",
    "    cs___.append(compute_cs(cost_matrix,soybean_test_label,predict_label))\n",
    "cs___ = np.array(cs___)\n",
    "# print(cs__)\n",
    "print(\"meta\",np.mean(cs___))\n",
    "print(\"meta\",np.std(cs___))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe98e6a-4415-4111-8ad1-7b20255e4c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 728.54\n",
      "C4.5 321.4660532622379\n",
      "undersampling 777.7850000000001\n",
      "undersampling 201.47332894207113\n",
      "oversampling 807.4350000000002\n",
      "oversampling 304.995695502412\n",
      "meta 620.925\n",
      "meta 194.3305839928445\n"
     ]
    }
   ],
   "source": [
    "lung_cancer = fetch_ucirepo(id=62) \n",
    "X = lung_cancer.data.features.values\n",
    "y = lung_cancer.data.targets.values\n",
    "unique = np.unique(y,return_counts=False)\n",
    "change = {unique[i]:i for i in range(len(unique))}\n",
    "y = [change[i[0]] for i in y]\n",
    "lung_ = pd.DataFrame(X)\n",
    "lung_[56] = y\n",
    "lun = lung_\n",
    "\n",
    "\n",
    "fea_cate = [3,37]\n",
    "fea_con = [i for i in range(lung_.shape[1]) if i not in fea_cate]\n",
    "\n",
    "lung_ = lung_[fea_cate].astype(str)\n",
    "lung_ = pd.get_dummies(lung_)\n",
    "index = [i for i in range(lung_.shape[1],lung_.shape[1]+len(fea_con))]\n",
    "\n",
    "lung_[index] = lun[fea_con].values\n",
    "\n",
    "lung_ = lung_.rename(columns={62:'Y'})\n",
    "\n",
    "cs = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    lung_train_set,lung_test_set = train_test_split(lung_,test_size=0.3)\n",
    "    lung_test_data = lung_test_set.iloc[:,:-1].values\n",
    "    lung_test_label = lung_test_set.iloc[:,-1].values\n",
    "    tree = D_Tree(lung_train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(lung_test_data)\n",
    "    predict_label = [int(i) for i in predict_label]\n",
    "    cs.append(compute_cs(cost_matrix,lung_test_label,predict_label))\n",
    "cs = np.array(cs)\n",
    "print(\"C4.5\",cs.mean())\n",
    "print(\"C4.5\",cs.std())\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    lung_train_set,lung_test_set = train_test_split(lung_,test_size=0.3)\n",
    "    lung_test_data = lung_test_set.iloc[:,:-1].values\n",
    "    lung_test_label = lung_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(lung_train_set,cost_matrix.values,'undersampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(lung_test_data)\n",
    "    predict_label = [int(i) for i in predict_label]\n",
    "    cs_.append(compute_cs(cost_matrix,lung_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "print(\"undersampling\",cs_.mean())\n",
    "print(\"undersampling\",cs_.std())\n",
    "\n",
    "cs__ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    lung_train_set,lung_test_set = train_test_split(lung_,test_size=0.3)\n",
    "    lung_test_data = lung_test_set.iloc[:,:-1].values\n",
    "    lung_test_label = lung_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(lung_train_set,cost_matrix.values,'oversampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(lung_test_data)\n",
    "    predict_label = [int(i) for i in predict_label]\n",
    "    cs__.append(compute_cs(cost_matrix,lung_test_label,predict_label))\n",
    "cs__ = np.array(cs__)\n",
    "print(\"oversampling\",cs__.mean())\n",
    "print(\"oversampling\",cs__.std())\n",
    "\n",
    "\n",
    "cs___=[]\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    lung_train_set,lung_test_set = train_test_split(lung_,test_size=0.3,random_state=42)\n",
    "    lung_test_data = lung_test_set.iloc[:,:-1].values\n",
    "    lung_test_label = lung_test_set.iloc[:,-1].values\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    meta = Metacost(lung_train_set,tree,cost_matrix.values,q=False)\n",
    "    model = meta.fit('Y')\n",
    "    predict_label = model.predict(lung_test_data)\n",
    "    predict_label = [int(i) for i in predict_label]\n",
    "    cs___.append(compute_cs(cost_matrix,lung_test_label,predict_label))\n",
    "cs___ = np.array(cs___)\n",
    "# print(cs__)\n",
    "print(\"meta\",np.mean(cs___))\n",
    "print(\"meta\",np.std(cs___))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee7ec43a-5551-4117-ad5c-c551df4d4b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 903.2861702127659\n",
      "C4.5 349.6383310486408\n",
      "undersampling 628.5021276595744\n",
      "undersampling 196.70470308890148\n",
      "meta 434.15957446808505\n",
      "meta 194.19949216438124\n"
     ]
    }
   ],
   "source": [
    "hepatitis = fetch_ucirepo(id=46) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = hepatitis.data.features.values \n",
    "y = hepatitis.data.targets.values\n",
    "unique = np.unique(y,return_counts=False)\n",
    "change = {unique[i]:i for i in range(len(unique))}\n",
    "y = [change[i[0]] for i in y]\n",
    "hep_ = pd.DataFrame(X)\n",
    "hep_[19] = y\n",
    "hep = hep_\n",
    "\n",
    "fea_cate = [2,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "fea_con = [i for i in range(hep_.shape[1]) if i not in fea_cate]\n",
    "\n",
    "hep_ = hep_[fea_cate].astype(str)\n",
    "hep_ = pd.get_dummies(hep_)\n",
    "index = [i for i in range(hep_.shape[1],hep_.shape[1]+len(fea_con))]\n",
    "\n",
    "hep_[index] = hep[fea_con].values\n",
    "\n",
    "hep_ = hep_.rename(columns={hep_.shape[1]-1:'Y'})\n",
    "\n",
    "\n",
    "cs = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    hep_train_set,hep_test_set = train_test_split(hep_,test_size=0.3)\n",
    "    hep_test_data = hep_test_set.iloc[:,:-1].values\n",
    "    hep_test_label = hep_test_set.iloc[:,-1].values\n",
    "    tree = D_Tree(hep_train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(hep_test_data)\n",
    "    predict_label = [int(i) for i in predict_label]\n",
    "    cs.append(compute_cs(cost_matrix,hep_test_label,predict_label))\n",
    "cs = np.array(cs)\n",
    "print(\"C4.5\",cs.mean())\n",
    "print(\"C4.5\",cs.std())\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    hep_train_set,hep_test_set = train_test_split(hep_,test_size=0.3)\n",
    "    hep_test_data = hep_test_set.iloc[:,:-1].values\n",
    "    hep_test_label = hep_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(hep_train_set,cost_matrix.values,'undersampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(hep_test_data)\n",
    "    predict_label = [int(i) for i in predict_label]\n",
    "    cs_.append(compute_cs(cost_matrix,hep_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "print(\"undersampling\",cs_.mean())\n",
    "print(\"undersampling\",cs_.std())\n",
    "\n",
    "# cs__ = []\n",
    "# for i in range(20):\n",
    "#     cost_matrix = make_cost_matrix(y)\n",
    "#     hep_train_set,hep_test_set = train_test_split(hep_,test_size=0.3)\n",
    "#     hep_test_data = hep_test_set.iloc[:,:-1].values\n",
    "#     hep_test_label = hep_test_set.iloc[:,-1].values\n",
    "#     train_set_x,train_set_y = stratified_sampling(hep_train_set,cost_matrix.values,'oversampling') \n",
    "#     train_set = pd.DataFrame(train_set_x)\n",
    "#     train_set['Y'] = train_set_y\n",
    "#     tree = D_Tree(train_set)\n",
    "#     tree.fit()\n",
    "#     predict_label = tree.predict(hep_test_data)\n",
    "#     predict_label = [int(i) for i in predict_label]\n",
    "#     cs__.append(compute_cs(cost_matrix,hep_test_label,predict_label))\n",
    "# cs__ = np.array(cs__)\n",
    "# print(\"oversampling\",cs__.mean())\n",
    "# print(\"oversampling\",cs__.std())\n",
    "\n",
    "cs___=[]\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    hep_train_set,lung_test_set = train_test_split(hep_,test_size=0.3,random_state=42)\n",
    "    hep_test_data = hep_test_set.iloc[:,:-1].values\n",
    "    hep_test_label = hep_test_set.iloc[:,-1].values\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    meta = Metacost(hep_train_set,tree,cost_matrix.values,q=False)\n",
    "    model = meta.fit('Y')\n",
    "    predict_label = model.predict(hep_test_data)\n",
    "    predict_label = [int(i) for i in predict_label]\n",
    "    cs___.append(compute_cs(cost_matrix,hep_test_label,predict_label))\n",
    "cs___ = np.array(cs___)\n",
    "# print(cs__)\n",
    "print(\"meta\",np.mean(cs___))\n",
    "print(\"meta\",np.std(cs___))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06bc96fe-d5d6-4fcf-ab47-3415bc58ee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 662.6341269841271\n",
      "C4.5 187.47579539579095\n",
      "under 655.9015873015873\n",
      "under 205.20203439692042\n",
      "under 501.2539682539683\n",
      "under 189.79595898454528\n",
      "meta 608.5666666666666\n",
      "meta 190.85111771557152\n"
     ]
    }
   ],
   "source": [
    "connectionist_bench_sonar_mines_vs_rocks = fetch_ucirepo(id=151) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = connectionist_bench_sonar_mines_vs_rocks.data.features.values \n",
    "y = connectionist_bench_sonar_mines_vs_rocks.data.targets.values\n",
    "\n",
    "unique = np.unique(y,return_counts=False)\n",
    "change = {unique[i]:i for i in range(len(unique))}\n",
    "y = [change[i[0]] for i in y]\n",
    "sonar_ = pd.DataFrame(X)\n",
    "sonar_['Y'] = y\n",
    "\n",
    "\n",
    "cs = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    sonar_train_set,sonar_test_set = train_test_split(sonar_,test_size=0.3)\n",
    "    sonar_test_data = sonar_test_set.iloc[:,:-1].values\n",
    "    sonar_test_label = sonar_test_set.iloc[:,-1].values\n",
    "    tree = D_Tree(sonar_train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(sonar_test_data)\n",
    "    cs.append(compute_cs(cost_matrix,sonar_test_label,predict_label))\n",
    "cs = np.array(cs)\n",
    "print(\"C4.5\",cs.mean())\n",
    "print(\"C4.5\",cs.std())\n",
    "\n",
    "cs_ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    sonar_train_set,sonar_test_set = train_test_split(sonar_,test_size=0.3)\n",
    "    sonar_test_data = sonar_test_set.iloc[:,:-1].values\n",
    "    sonar_test_label = sonar_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(sonar_train_set,cost_matrix.values,'undersampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(sonar_test_data)\n",
    "    cs_.append(compute_cs(cost_matrix,sonar_test_label,predict_label))\n",
    "cs_ = np.array(cs_)\n",
    "print(\"under\",cs_.mean())\n",
    "print(\"under\",cs_.std())\n",
    "\n",
    "cs__ = []\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    sonar_train_set,soybean_test_set = train_test_split(sonar_,test_size=0.3)\n",
    "    sonar_test_data = sonar_test_set.iloc[:,:-1].values\n",
    "    sonar_test_label = sonar_test_set.iloc[:,-1].values\n",
    "    train_set_x,train_set_y = stratified_sampling(sonar_train_set,cost_matrix.values,'oversampling') \n",
    "    train_set = pd.DataFrame(train_set_x)\n",
    "    train_set['Y'] = train_set_y\n",
    "    tree = D_Tree(train_set)\n",
    "    tree.fit()\n",
    "    predict_label = tree.predict(sonar_test_data)\n",
    "    cs__.append(compute_cs(cost_matrix,sonar_test_label,predict_label))\n",
    "cs__ = np.array(cs__)\n",
    "print(\"under\",cs__.mean())\n",
    "print(\"under\",cs__.std())\n",
    "\n",
    "\n",
    "cs___=[]\n",
    "for i in range(20):\n",
    "    cost_matrix = make_cost_matrix(y)\n",
    "    sonar_train_set,sonar_test_set = train_test_split(sonar_,test_size=0.3,random_state=42)\n",
    "    sonar_test_data = sonar_test_set.iloc[:,:-1].values\n",
    "    sonar_test_label = sonar_test_set.iloc[:,-1].values\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    meta = Metacost(sonar_train_set,tree,cost_matrix.values,q=False)\n",
    "    model = meta.fit('Y')\n",
    "    predict_label = model.predict(sonar_test_data)\n",
    "    cs___.append(compute_cs(cost_matrix,sonar_test_label,predict_label))\n",
    "cs___ = np.array(cs___)\n",
    "# print(cs__)\n",
    "print(\"meta\",np.mean(cs___))\n",
    "print(\"meta\",np.std(cs___))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecd60e-60d2-48f5-b420-b38d6a5649c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
